# AI-PDFSearcher

Моё веб-приложение на **Flask** использует различные модели машинного обучения для анализа текста в **PDF-документах**. Оно поддерживает функционал извлечения текста как напрямую из **PDF**, так и из изображений внутри них, ответы на вопросы, основанные на тексте, и создание резюме текста.

## Основные функции и рабочий процесс:

### Извлечение текста из PDF и изображений:

Для извлечения текста я использую довольн известную библиотеку которая позволяет распознавать и “**читать**” текст, встроенный в изображения. **Python-tesseract** - это инструмент оптического распознавания символов (OCR) для python.

Тут я написал функцию которая должна отделять текст от фотографии с помощью **Tesseract**, также добавив расширения в плане языков, теперь библиотека может читать русский также как и английский язык:

```
    import pytesseract
    
    def extract_text_from_image(image_path):
        try:
            image = Image.open(image_path)
            text = pytesseract.image_to_string(image, lang='rus+eng')
            print(f"Extracted text from image: {text[:200]}...")
            return text
```
- Открывает изображение по указанному пути с помощью `Image.open(image_path)`.
- Извлекает текст из изображения с использованием `pytesseract.image_to_string(image, lang='rus+eng')`, задав языки для распознавания текста как русский и английский.
- Печатает первые 200 символов извлеченного текста для проверки.
- Возвращает извлеченный текст.

```
except Exception as e:
    print(f"Failed to extract text from image: {e}")
    return None
```

Если возникает ошибка при открытии изображения или извлечении текста, печатает сообщение об ошибке и возвращает `None`.

> [!NOTE]  
> Этот код использует следующие компоненты:
>
> Библиотека pytesseract для оптического распознавания текста (OCR).
> 
> Библиотека PIL (Pillow) для работы с изображениями (импортируется через Image).

В дальнейшем мною был написан кусок кода который позволяет работать функции сверху, а именно была использована библиотека Fitz/PyMuPDF для просмотра, рендеринга и инструментов для работы с такими форматами как PDF, XPS, OpenXPS, CBZ, EPUB и FB2.

```
pdf_document = fitz.open(temp_pdf_path)
```

Открывает PDF-документ, находящийся по пути temp_pdf_path, с использованием библиотеки PyMuPDF (импортируемой как fitz).

```
for page_num in range(len(pdf_document)):
    page = pdf_document.load_page(page_num)
```
Проходит по каждой странице PDF-документа, загружая страницу по номеру.

```
images = page.get_images(full=True)
for img_index, img in enumerate(images):
    xref = img[0]
    base_image = pdf_document.extract_image(xref)
    image_bytes = base_image["image"]
    image_ext = base_image["ext"]
    image_path = os.path.join(temp_dir, f"image{page_num+1}_{img_index+1}.{image_ext}")
    with open(image_path, "wb") as image_file:
        image_file.write(image_bytes)
```

**Для каждого изображения:**
- Получает ссылку на изображение xref.
- Извлекает изображение с помощью pdf_document.extract_image(xref).
- Получает байты изображения и его расширение.
- Формирует путь для сохранения изображения.
- Сохраняет изображение в файл по указанному пути.

```
text = extract_text_from_image(image_path)
if text:
    combined_text += " " + text
```

Использует функцию extract_text_from_image для извлечения текста из сохраненных изображений. Если текст найден, добавляет его к переменной combined_text.

> [!NOTE]
> 
>Этот код использует следующие компоненты:
>
>Библиотека PyMuPDF (fitz) для работы с PDF-документами и извлечения изображений.
>
>Библиотека pytesseract для оптического распознавания текста (OCR).
>
>Библиотека PIL (Pillow) для работы с изображениями.

### Хранения PDF-файлов во временном хранилище:

    import tempfile
    
    temp_dir = tempfile.mkdtemp()
    temp_pdf_path = os.path.join(temp_dir, pdf_file.filename)
    pdf_file.save(temp_pdf_path)

Функция `tempfile.mkdtemp()` создает временный каталог и возвращает путь к нему.

С помощью функции `os.path.join` формируется полный путь к временному **PDF-файлу**, используя имя исходного файла `pdf_file.filename` и путь к временному каталогу `temp_dir`.

Используя метод `save` объекта `pdf_file`, PDF-файл сохраняется по сформированному временному пути `temp_pdf_path`.

### Анализ текста с предварительно обученными моделями:

1. Подготавливает список предложений из текста:
```
    sentences = [sent.strip() for sent in cleaned_text.split('.') if sent.strip()]
```
Разбивает текст `cleaned_text` на предложения по точке и удаляет пустые строки и пробелы.

2. Создает векторное представление для каждого предложения:
```
    sentence_vectors = []
    for sentence in sentences:
        vec = torch.tensor(nlp(sentence)).mean(dim=1).numpy().flatten()
        if vec.ndim == 1:
            sentence_vectors.append(vec)
        else:
            print(f"Skipping sentence due to incorrect vector shape: {sentence}")
```
**Для каждого предложения:**

- Преобразует предложение в векторное представление с использованием модели nlp.
- Берет среднее значение вдоль первого измерения вектора и преобразует его в numpy массив.
- Проверяет, что вектор имеет правильную форму (одномерный массив). Если это так, добавляет его в sentence_vectors, иначе пропускает предложение.
- 
3. Проверяет, удалось ли векторизовать предложения:
  
```
    if len(sentence_vectors) == 0:
        return jsonify({"summary": "Failed to vectorize sentences."})
```

4. Преобразует список векторов в массив numpy:

```
    sentence_vectors = np.array(sentence_vectors)
    print(f"Shape of sentence_vectors: {sentence_vectors.shape}")
```

5. Создает и добавляет векторы в FAISS индекс:

```
    dimension = sentence_vectors.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(sentence_vectors)
```
- Определяет размерность векторов.
- Создает индекс FAISS для поиска по близости (`IndexFlatL2`).
- Добавляет векторы предложений в индекс.

### Создание пользовательского запроса:

```
    query_vector = torch.tensor(nlp(query)).mean(dim=1).numpy().flatten().reshape(1, -1)
    print(f"Query vector shape: {query_vector.shape}")
```
### Выполнения поиск в FAISS индексе
```
    k = 10  # number of top relevant results to retrieve
```

Устанавливает значение k равным 10, что означает, что будут извлекаться 10 наиболее релевантных результатов.

```
    distances, indices = index.search(query_vector, k)
```

Использует метод search индекса FAISS для поиска ближайших k векторов к query_vector. Возвращает расстояния до этих векторов и их индексы.

```
    relevant_snippets = [sentences[i] for i in indices[0]]
```
Использует индексы, возвращенные FAISS, для извлечения соответствующих предложений из списка sentences.

### Уникальность и непохожесть фрагментов
```
    import difflib

    # Ensure unique and non-similar snippets
    unique_snippets = list(dict.fromkeys(relevant_snippets))
    filtered_snippets = []
    for snippet in unique_snippets:
        if not any(difflib.SequenceMatcher(None, snippet, filtered_snippet).ratio() > 0.7 for filtered_snippet in filtered_snippets):
            filtered_snippets.append(snippet)
```

Использует словарь для удаления дубликатов из списка `relevant_snippets` и сохраняет только уникальные фрагменты текста.

**Для каждого уникального фрагмента:**

- Проверяет, не является ли он слишком похожим (более чем на 70%) на уже добавленные фрагменты в filtered_snippets.
- Если фрагмент не слишком похож, добавляет его в filtered_snippets.

### Создание резюме и генерация ответ

Соединяет все фрагменты из `filtered_snippets` в одну строку, разделяя их пробелами:
```
combined_snippets = " ".join(filtered_snippets)
```
Использует модель `llama_model` для генерации краткого содержания на основе объединенных фрагментов текста. Ограничивает длину генерируемого текста 500 символами:
```
summary = llama_model(combined_snippets, max_length=500)[0]['generated_text']
```

Отправляет модель `llama_model` запрос, включающий вопрос и созданное краткое содержание, чтобы получить ответ. Ограничивает длину ответа 500 символами:
```
response = llama_model(f"Вопрос: {query}\nТекст: {summary}\nОтвет:", max_length=500)
```
                                                                                                                                                                                                                                                                            
### Веб-интерфейс:

Позволяет пользователям загружать PDF-файлы и отправлять запросы о их содержимом.
Бэкенд обрабатывает эти входные данные, обрабатывает PDF и возвращает ответ в формате JSON на основе запроса.

### Определения конечных точек:

@app.route('/analyze', methods=['POST']): Обрабатывает загрузку PDF-файла и запрос, обрабатывает PDF с использованием вышеупомянутых методов и возвращает JSON-ответ с результатами запроса.

## Потенциальные проблемы и рекомендации:

### Обработка ошибок:

Приложение пытается управлять исключениями во время извлечения текста, но также должно обрабатывать потенциальные ошибки в прогнозах модели (ответы на вопросы и резюмирование) и других частях процесса обработки PDF.

### Оптимизация производительности:

Обработка PDF, особенно извлечение текста в виде изображений, может потреблять много ресурсов. Исследую возможности оптимизации этих процессов или настройку системы очередей для эффективного управления нагрузкой.

### Вопросы безопасности:

Особое внимание уделяю безопасной обработке файлов, чтобы предотвратить обработку вредоносных файлов и проверяю файлы на соответствие легитимным PDF, санитизируя все входные данные.

### Пользовательский интерфейс:

Фронтенд предоставляет базовые функциональные возможности, но его можно улучшить для удобства использования, например, отображая индикатор прогресса во время обработки и предоставляя более подробную обратную связь о состоянии запроса.

### Масштабируемость:

Поскольку приложение зависит от интенсивных задач обработки, масштабирование может потребовать распределенной обработки или использования более мощных серверов, особенно при ожидании высокой нагрузки.
Этот анализ очерчивает основные функциональные возможности и потенциальные области улучшения вашего приложения. Если вам нужны более конкретные детали по любому конкретному аспекту, пожалуйста, дайте знать!

### Мой опыт работы над проектом 

При написании своего веб-приложения на Flask я столкнулся с необходимостью использования множества различных технологий, начиная от фреймворков и библиотек для обработки PDF и изображений до векторных баз данных и систем управления базами данных. Этот проект позволил мне глубоко погрузиться в мир векторных баз данных, таких как Malvius, и традиционных систем управления базами данных, включая PostgreSQL и SQLite.

Особенно сложной задачей стало настройка локального сервера для баз данных. Мне нужно было убедиться, что сервер стабильно работает и способен обрабатывать запросы в режиме реального времени, особенно когда речь идет о выгрузке и обработке больших PDF-файлов. Я разработал систему, которая конвертирует PDF-страницы в изображения, затем из этих изображений извлекает текст с помощью OCR (оптическое распознавание символов) и загружает его в базу данных. В некоторых случаях текст извлекался напрямую из PDF и также отправлялся в базу данных.

Работа с различными форматами данных и интеграция их в единую систему была настоящим вызовом. Каждый этап процесса, от конвертации PDF до извлечения текста и его сохранения в базу данных, требовал тщательной настройки и оптимизации. Я многократно сталкивался с проблемами производительности и сбоями, которые требовали тщательного анализа и исправления. Оптимизация запросов к базе данных и управление памятью сервера стали ключевыми аспектами для обеспечения эффективности и надежности приложения.

Этот опыт позволил мне значительно улучшить мои навыки в области разработки веб-приложений и работы с базами данных, дав глубокое понимание взаимодействия различных технологий и подходов в современной разработке программного обеспечения.






